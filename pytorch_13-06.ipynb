{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOwheUQyFQqkrVOBN0PITka"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**06 사전 훈련된 임베딩을 이용한 성능 상승 시키기**"],"metadata":{"id":"pt3ykAH7WGpH"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":593},"id":"okSW4-7IWCou","executionInfo":{"status":"error","timestamp":1709453503118,"user_tz":-540,"elapsed":89068,"user":{"displayName":"김재승","userId":"10280980096726140552"}},"outputId":"abdce9be-2207-45e4-b371-5138fe6a842c"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["X_data : 50000\n","y_data : 50000\n","------훈련 데이터의 비율-------\n","부정 리뷰 = 50.0%\n","긍정 리뷰 = 50.0%\n","------검증 데이터의 비율-------\n","부정 리뷰 = 50.0%\n","긍정 리뷰 = 50.0%\n","------테스트 데이터의 비율-------\n","부정 리뷰 = 50.0%\n","긍정 리뷰 = 50.0%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20000/20000 [00:33<00:00, 597.18it/s]\n","100%|██████████| 5000/5000 [00:07<00:00, 656.39it/s]\n","100%|██████████| 25000/25000 [00:40<00:00, 610.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["총 단어수 : 100586\n","단어 집합의 크기 : 100586\n","등장 빈도가 2번 이하인 희귀 단어의 수: 61877\n","단어 집합에서 희귀 단어의 비율 : 61.51651323245779\n","전체 등장 빈도에서 희귀 단어 등장 빈도 비율 : 1.3294254426463437\n","단어 집합의 크기 38711\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'below_threshold_len' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-2bd1bab555f1>\u001b[0m in \u001b[0;36m<cell line: 132>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;31m#길이 500으로 패딩\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m \u001b[0mbelow_threshold_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_X_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;31m#패딩 함수 정의\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'below_threshold_len' is not defined"]}],"source":["##데이터 로드 및 단어 토큰화\n","\n","#import\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import nltk\n","import torch\n","import urllib.request\n","from tqdm import tqdm\n","from collections import Counter\n","from nltk.tokenize import word_tokenize\n","from sklearn.model_selection import train_test_split\n","\n","nltk.download('punkt')\n","\n","#데이터 로드\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/pytorch-nlp-tutorial/main/10.%20RNN%20Text%20Classification/dataset/IMDB%20Dataset.csv\", filename=\"IMDB Dataset.csv\")\n","\n","df = pd.read_csv('IMDB Dataset.csv')\n","df.head()\n","\n","#레이블 변환\n","df['sentiment'] = df['sentiment'].replace(['positive','negative'],[1,0])\n","df.head()\n","\n","#데이터 정의\n","X_data = df['review']\n","y_data = df['sentiment']\n","print('X_data :', len(X_data))\n","print(\"y_data :\", len(y_data))\n","\n","#훈련 / 검증 / 테스트 데이터\n","X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.5, random_state =0, stratify = y_data)\n","X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state=0, stratify= y_train)\n","\n","print('------훈련 데이터의 비율-------')\n","print(f\"부정 리뷰 = {round(y_train.value_counts()[0]/len(y_train)*100,3)}%\")\n","print(f\"긍정 리뷰 = {round(y_train.value_counts()[1]/len(y_train)*100,3)}%\")\n","print('------검증 데이터의 비율-------')\n","print(f\"부정 리뷰 = {round(y_valid.value_counts()[0]/len(y_valid)*100,3)}%\")\n","print(f\"긍정 리뷰 = {round(y_valid.value_counts()[1]/len(y_valid)*100,3)}%\")\n","print('------테스트 데이터의 비율-------')\n","print(f\"부정 리뷰 = {round(y_test.value_counts()[0]/len(y_test)*100,3)}%\")\n","print(f\"긍정 리뷰 = {round(y_test.value_counts()[1]/len(y_test)*100,3)}%\")\n","\n","#토큰화\n","\n","#토큰화 함수 정의\n","\n","def tokenize(sentences):\n","    tokenized_sentences = []\n","    for sent in tqdm(sentences):\n","        tokenized_sent = word_tokenize(sent)\n","        tokenized_sent = [word.lower() for word in tokenized_sent]\n","        tokenized_sentences.append(tokenized_sent)\n","    return tokenized_sentences\n","\n","tokenized_X_train = tokenize(X_train)\n","tokenized_X_valid = tokenize(X_valid)\n","tokenized_X_test = tokenize(X_test)\n","\n","#Vocab 만들기\n","\n","word_list = []\n","for sent in tokenized_X_train:\n","    for word in sent:\n","        word_list.append(word)\n","\n","word_counts = Counter(word_list)\n","print('총 단어수 :', len(word_counts))\n","\n","#빈도수 낮은 데이터 배제\n","vocab = sorted(word_counts, key = word_counts.get, reverse=True)\n","\n","\n","#빈도수 3회 미만의 데이터\n","threshold = 3\n","total_cnt = len(word_counts)\n","rare_cnt = 0\n","total_freq = 0\n","rare_freq = 0\n","\n","for key, value in word_counts.items():\n","    total_freq = total_freq + value\n","\n","    if(value < threshold):\n","        rare_cnt = rare_cnt + 1\n","        rare_freq = rare_freq + value\n","\n","print('단어 집합의 크기 :', total_cnt)\n","print(f'등장 빈도가 {threshold -1}번 이하인 희귀 단어의 수: {rare_cnt}')\n","print('단어 집합에서 희귀 단어의 비율 :', (rare_cnt / total_cnt)*100)\n","print('전체 등장 빈도에서 희귀 단어 등장 빈도 비율 :', (rare_freq / total_freq)*100)\n","\n","# 빈도수 2 이하 단어 제거\n","vocab_size = total_cnt - rare_cnt\n","vocab = vocab[:vocab_size]\n","\n","#정수 부여\n","word_to_index = {}\n","word_to_index['<PAD>'] = 0\n","word_to_index['<UNK>'] = 1\n","\n","for index, word in enumerate(vocab):\n","    word_to_index[word] = index +2\n","\n","vocab_size = len(word_to_index)\n","print('단어 집합의 크기', vocab_size)\n","\n","#정수 인코딩\n","\n","#인코딩 함수\n","def texts_to_sequences(tokenized_X_data, word_to_index):\n","    encoded_X_data = []\n","    for sent in tokenized_X_data:\n","        index_sequences = []\n","        for word in sent:\n","            try:\n","                index_sequences.append(word_to_index[word])\n","            except KeyError:\n","                index_sequences.append(word_to_index['<UNK>'])\n","        encoded_X_data.append(index_sequences)\n","    return encoded_X_data\n","\n","encoded_X_train = texts_to_sequences(tokenized_X_train, word_to_index)\n","encoded_X_valid = texts_to_sequences(tokenized_X_valid, word_to_index)\n","encoded_X_test = texts_to_sequences(tokenized_X_test, word_to_index)\n","\n"]},{"cell_type":"code","source":["#길이 500으로 패딩\n","max_len = 500\n","#패딩 함수 정의\n","def pad_sequences(sentences, max_len):\n","    features = np.zeros((len(sentences), max_len), dtype = int)\n","    for index, sentence in enumerate(sentences):\n","        if len(sentence) != 0:\n","            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n","    return features\n","\n","padded_X_train = pad_sequences(encoded_X_train, max_len=max_len)\n","padded_X_valid = pad_sequences(encoded_X_valid, max_len=max_len)\n","padded_X_test = pad_sequences(encoded_X_test, max_len=max_len)\n","\n","print('훈련데이터 :', padded_X_train.shape)\n","print('검증 데이터 :', padded_X_valid.shape)\n","print('테스트 데이터 :', padded_X_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4QpWs0rGWqJR","executionInfo":{"status":"ok","timestamp":1709453561977,"user_tz":-540,"elapsed":1171,"user":{"displayName":"김재승","userId":"10280980096726140552"}},"outputId":"8352e47d-0b7d-421f-fde9-93df8a7fdd92"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련데이터 : (20000, 500)\n","검증 데이터 : (5000, 500)\n","테스트 데이터 : (25000, 500)\n"]}]},{"cell_type":"code","source":["#사전 훈련된 임베딩\n","\n","#gensim 설치\n","!pip install gensim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ILFtqVlX0gF","executionInfo":{"status":"ok","timestamp":1709453716728,"user_tz":-540,"elapsed":6727,"user":{"displayName":"김재승","userId":"10280980096726140552"}},"outputId":"03a9cedc-f8af-4f17-a8e6-e95021f6dbfd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"]}]},{"cell_type":"code","source":["#사전 훈련된 워드 임베딩 다운로드\n","!pip install gdown\n","\n","!gdown https://drive.google.com/uc?id=1Av37IVBQAAntSe1X3MOAl5gvowQzd2_j\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KlTWHkz-YYqj","executionInfo":{"status":"ok","timestamp":1709453765187,"user_tz":-540,"elapsed":39708,"user":{"displayName":"김재승","userId":"10280980096726140552"}},"outputId":"637ab3af-49e6-4793-8781-0b8ceb0cc1e9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Downloading...\n","From (original): https://drive.google.com/uc?id=1Av37IVBQAAntSe1X3MOAl5gvowQzd2_j\n","From (redirected): https://drive.google.com/uc?id=1Av37IVBQAAntSe1X3MOAl5gvowQzd2_j&confirm=t&uuid=af2d65c6-6b38-4dca-85c7-838b8bab8f2a\n","To: /content/GoogleNews-vectors-negative300.bin.gz\n","100% 1.65G/1.65G [00:27<00:00, 59.9MB/s]\n"]}]},{"cell_type":"code","source":["import gensim\n","\n","#사전 훈련된 Word2vec 모델을 로드\n","word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n"],"metadata":{"id":"ymy7TH5SYcX3","executionInfo":{"status":"ok","timestamp":1709453916683,"user_tz":-540,"elapsed":51369,"user":{"displayName":"김재승","userId":"10280980096726140552"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["embedding_matrix = np.zeros((vocab_size, 300))"],"metadata":{"id":"u36tKcamYtUN","executionInfo":{"status":"ok","timestamp":1709453924612,"user_tz":-540,"elapsed":5,"user":{"displayName":"김재승","userId":"10280980096726140552"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#맵핑\n","\n","def get_vector(word):\n","    if word in word2vec_model:\n","        return word2vec_model[word]\n","    else:\n","        return None\n","\n","for word, i in word_to_index.items():\n","    if i>2:\n","        temp = get_vector(word)\n","        if temp is not None:\n","            embedding_matrix[i] = temp\n","\n","embedding_matrix[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Co4shrepZNVD","executionInfo":{"status":"ok","timestamp":1709454055079,"user_tz":-540,"elapsed":8,"user":{"displayName":"김재승","userId":"10280980096726140552"}},"outputId":"7b217785-31a0-4fa1-fd7a-9b94e2edcc0a"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["word_to_index['apple']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0PK_o7yEZs_0","executionInfo":{"status":"ok","timestamp":1709454066199,"user_tz":-540,"elapsed":6,"user":{"displayName":"김재승","userId":"10280980096726140552"}},"outputId":"919a44fd-3e58-46f2-e67c-65452e6ee217"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8053"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["train_label_tensor = torch.tensor(np.array(y_train))\n","valid_label_tensor = torch.tensor(np.array(y_valid))\n","test_label_tensor = torch.tensor(np.array(y_test))\n","print(train_label_tensor[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M9K9DzGOaUg9","executionInfo":{"status":"ok","timestamp":1709454217407,"user_tz":-540,"elapsed":6,"user":{"displayName":"김재승","userId":"10280980096726140552"}},"outputId":"e9fd33e2-771a-43f1-8117-973a40e98acd"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 1, 0, 0, 0])\n"]}]},{"cell_type":"code","source":["#모델링\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","USE_CUDA = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n","print(\"cpu와 cuda 중 다음 기기로 학습함:\", device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cbDMLT0hZvqM","executionInfo":{"status":"ok","timestamp":1709454219320,"user_tz":-540,"elapsed":10,"user":{"displayName":"김재승","userId":"10280980096726140552"}},"outputId":"0078188c-216c-4a81-8681-a4a2a33a7110"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu와 cuda 중 다음 기기로 학습함: cuda\n"]}]},{"cell_type":"code","source":["class CNN(torch.nn.Module):\n","  def __init__(self, vocab_size, num_labels):\n","    super(CNN, self).__init__()\n","\n","    # 오직 하나의 종류의 필터만 사용함.\n","    self.num_filter_sizes = 1 # 윈도우 5짜리 1개만 사용\n","    self.num_filters = 256\n","\n","    # 주석 처리된 코드는 기존의 임베딩 층을 사용할 경우\n","    # self.word_embed = nn.Embedding(num_embeddings=vocab_size, embedding_dim=128, padding_idx=0)\n","    self.word_embed = nn.Embedding(num_embeddings=vocab_size, embedding_dim=300)\n","    self.word_embed.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n","    self.word_embed.weight.requires_grad = True\n","\n","    # 윈도우 5짜리 1개만 사용\n","    self.conv1 = torch.nn.Conv1d(300, self.num_filters, 5, stride=1)\n","    self.dropout = torch.nn.Dropout(0.5)\n","    self.fc1 = torch.nn.Linear(1 * self.num_filters, num_labels, bias=True)\n","\n","  def forward(self, inputs):\n","    # word_embed(inputs).shape == (배치 크기, 문장길이, 임베딩 벡터의 차원)\n","    # word_embed(inputs).permute(0, 2, 1).shape == (배치 크기, 임베딩 벡터의 차원, 문장 길이)\n","    embedded = self.word_embed(inputs).permute(0, 2, 1)\n","\n","    # max를 이용한 maxpooling\n","    # conv1(embedded).shape == (배치 크기, 커널 개수, 컨볼루션 연산 결과) == ex) 32, 256, 496\n","    # conv1(embedded).permute(0, 2, 1).shape == (배치 크기, 컨볼루션 연산 결과, 커널 개수)\n","    # conv1(embedded).permute(0, 2, 1).max(1)[0]).shape == (배치 크기, 커널 개수)\n","    x = F.relu(self.conv1(embedded).permute(0, 2, 1).max(1)[0])\n","\n","    # y_pred.shape == (배치 크기, 분류할 카테고리의 수)\n","    y_pred = self.fc1(self.dropout(x))\n","\n","    return y_pred\n"],"metadata":{"id":"MqpQ1ce3Z19b","executionInfo":{"status":"ok","timestamp":1709454219321,"user_tz":-540,"elapsed":9,"user":{"displayName":"김재승","userId":"10280980096726140552"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["encoded_train = torch.tensor(padded_X_train).to(torch.int64)\n","train_dataset = torch.utils.data.TensorDataset(encoded_train, train_label_tensor)\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=32)\n","\n","encoded_test = torch.tensor(padded_X_test).to(torch.int64)\n","test_dataset = torch.utils.data.TensorDataset(encoded_test, test_label_tensor)\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=1)\n","\n","encoded_valid = torch.tensor(padded_X_valid).to(torch.int64)\n","valid_dataset = torch.utils.data.TensorDataset(encoded_valid, valid_label_tensor)\n","valid_dataloader = torch.utils.data.DataLoader(valid_dataset, shuffle=True, batch_size=1)\n"],"metadata":{"id":"BIMJVTCCZ4qZ","executionInfo":{"status":"ok","timestamp":1709454219321,"user_tz":-540,"elapsed":6,"user":{"displayName":"김재승","userId":"10280980096726140552"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["total_batch = len(train_dataloader)\n","print('총 배치의 수 : {}'.format(total_batch))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TYJQOyFoZ5-D","executionInfo":{"status":"ok","timestamp":1709454229396,"user_tz":-540,"elapsed":437,"user":{"displayName":"김재승","userId":"10280980096726140552"}},"outputId":"c58cb129-da4a-4207-c9c8-3853230dd38b"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["총 배치의 수 : 625\n"]}]},{"cell_type":"code","source":["model = CNN(vocab_size, num_labels = len(set(y_train)))\n","model.to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G4iBJ3x-aXn3","executionInfo":{"status":"ok","timestamp":1709454233442,"user_tz":-540,"elapsed":1054,"user":{"displayName":"김재승","userId":"10280980096726140552"}},"outputId":"908e3737-99ad-49f9-edb8-8df142299069"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CNN(\n","  (word_embed): Embedding(38711, 300)\n","  (conv1): Conv1d(300, 256, kernel_size=(5,), stride=(1,))\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc1): Linear(in_features=256, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"],"metadata":{"id":"uHl2DkZgaYhi","executionInfo":{"status":"ok","timestamp":1709454240862,"user_tz":-540,"elapsed":3072,"user":{"displayName":"김재승","userId":"10280980096726140552"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def calculate_accuracy(logits, labels):\n","    # _, predicted = torch.max(logits, 1)\n","    predicted = torch.argmax(logits, dim=1)\n","    correct = (predicted == labels).sum().item()\n","    total = labels.size(0)\n","    accuracy = correct / total\n","    return accuracy\n"],"metadata":{"id":"SIBZ_i3CaZ4X","executionInfo":{"status":"ok","timestamp":1709454241364,"user_tz":-540,"elapsed":20,"user":{"displayName":"김재승","userId":"10280980096726140552"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, valid_dataloader, criterion, device):\n","    val_loss = 0\n","    val_correct = 0\n","    val_total = 0\n","\n","    model.eval()\n","    with torch.no_grad():\n","        # 데이터로더로부터 배치 크기만큼의 데이터를 연속으로 로드\n","        for batch_X, batch_y in valid_dataloader:\n","            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n","\n","            # 모델의 예측값\n","            logits = model(batch_X)\n","\n","            # 손실을 계산\n","            loss = criterion(logits, batch_y)\n","\n","            # 정확도와 손실을 계산함\n","            val_loss += loss.item()\n","            val_correct += calculate_accuracy(logits, batch_y) * batch_y.size(0)\n","            val_total += batch_y.size(0)\n","\n","    val_accuracy = val_correct / val_total\n","    val_loss /= len(valid_dataloader)\n","\n","    return val_loss, val_accuracy\n"],"metadata":{"id":"uDmVp56aaaoN","executionInfo":{"status":"ok","timestamp":1709454245834,"user_tz":-540,"elapsed":430,"user":{"displayName":"김재승","userId":"10280980096726140552"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["num_epochs = 5\n","\n","# Training loop\n","best_val_loss = float('inf')\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    # Training\n","    train_loss = 0\n","    train_correct = 0\n","    train_total = 0\n","    model.train()\n","    for batch_X, batch_y in train_dataloader:\n","        # Forward pass\n","        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n","        # batch_X.shape == (batch_size, max_len)\n","        logits = model(batch_X)\n","\n","        # Compute loss\n","        loss = criterion(logits, batch_y)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Calculate training accuracy and loss\n","        train_loss += loss.item()\n","        train_correct += calculate_accuracy(logits, batch_y) * batch_y.size(0)\n","        train_total += batch_y.size(0)\n","\n","    train_accuracy = train_correct / train_total\n","    train_loss /= len(train_dataloader)\n","\n","    # Validation\n","    val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}:')\n","    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n","    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","    # 검증 손실이 최소일 때 체크포인트 저장\n","    if val_loss < best_val_loss:\n","        print(f'Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. 체크포인트를 저장합니다.')\n","        best_val_loss = val_loss\n","        torch.save(model.state_dict(), 'best_model_checkpoint.pth')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9VDYZfFabvh","executionInfo":{"status":"ok","timestamp":1709454313619,"user_tz":-540,"elapsed":63962,"user":{"displayName":"김재승","userId":"10280980096726140552"}},"outputId":"8850221f-37eb-4e11-ffd4-369e8543f947"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5:\n","Train Loss: 0.3764, Train Accuracy: 0.8266\n","Validation Loss: 0.2577, Validation Accuracy: 0.8928\n","Validation loss improved from inf to 0.2577. 체크포인트를 저장합니다.\n","Epoch 2/5:\n","Train Loss: 0.1843, Train Accuracy: 0.9299\n","Validation Loss: 0.2713, Validation Accuracy: 0.8912\n","Epoch 3/5:\n","Train Loss: 0.0770, Train Accuracy: 0.9747\n","Validation Loss: 0.3170, Validation Accuracy: 0.8918\n","Epoch 4/5:\n","Train Loss: 0.0309, Train Accuracy: 0.9903\n","Validation Loss: 0.3883, Validation Accuracy: 0.8976\n","Epoch 5/5:\n","Train Loss: 0.0182, Train Accuracy: 0.9946\n","Validation Loss: 0.4647, Validation Accuracy: 0.8892\n"]}]},{"cell_type":"code","source":["# 모델 로드\n","model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n","\n","# 모델을 device에 올립니다.\n","model.to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WU9iAThnacrq","executionInfo":{"status":"ok","timestamp":1709454313622,"user_tz":-540,"elapsed":35,"user":{"displayName":"김재승","userId":"10280980096726140552"}},"outputId":"4907823d-56f0-4c8f-8772-c9b5a40488b1"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CNN(\n","  (word_embed): Embedding(38711, 300)\n","  (conv1): Conv1d(300, 256, kernel_size=(5,), stride=(1,))\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc1): Linear(in_features=256, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["# 검증 데이터에 대한 정확도와 손실 계산\n","val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n","\n","print(f'Best model validation loss: {val_loss:.4f}')\n","print(f'Best model validation accuracy: {val_accuracy:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WOmum0IHadzt","executionInfo":{"status":"ok","timestamp":1709454318207,"user_tz":-540,"elapsed":4615,"user":{"displayName":"김재승","userId":"10280980096726140552"}},"outputId":"aa8aaeff-ab1c-417f-bd63-696b4ba9b3f5"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Best model validation loss: 0.2577\n","Best model validation accuracy: 0.8928\n"]}]},{"cell_type":"code","source":["# 테스트 데이터에 대한 정확도와 손실 계산\n","test_loss, test_accuracy = evaluate(model, test_dataloader, criterion, device)\n","\n","print(f'Best model test loss: {test_loss:.4f}')\n","print(f'Best model test accuracy: {test_accuracy:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XpJcgriRael_","executionInfo":{"status":"ok","timestamp":1709454332834,"user_tz":-540,"elapsed":14655,"user":{"displayName":"김재승","userId":"10280980096726140552"}},"outputId":"48973ec6-2199-4b90-ee45-54b2f5cb5348"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Best model test loss: 0.2574\n","Best model test accuracy: 0.8942\n"]}]},{"cell_type":"code","source":["index_to_tag = {0 : '부정', 1 : '긍정'}\n","\n","def predict(text, model, word_to_index, index_to_tag):\n","    # 모델 평가 모드\n","    model.eval()\n","\n","    # 토큰화 및 정수 인코딩. OOV 문제 발생 시 <UNK> 토큰에 해당하는 인덱스 1 할당\n","    tokens = word_tokenize(text)\n","    token_indices = [word_to_index.get(token.lower(), 1) for token in tokens]\n","\n","    # 리스트를 텐서로 변경\n","    input_tensor = torch.tensor([token_indices], dtype=torch.long).to(device)  # (1, seq_length)\n","\n","    # 모델의 예측\n","    with torch.no_grad():\n","        logits = model(input_tensor)  # (1, output_dim)\n","\n","    # 레이블 인덱스 예측\n","    _, predicted_index = torch.max(logits, dim=1)  # (1,)\n","\n","    # 인덱스와 매칭되는 카테고리 문자열로 변경\n","    predicted_tag = index_to_tag[predicted_index.item()]\n","\n","    return predicted_tag\n"],"metadata":{"id":"9MA3FiMUafTy","executionInfo":{"status":"ok","timestamp":1709454332835,"user_tz":-540,"elapsed":52,"user":{"displayName":"김재승","userId":"10280980096726140552"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["test_input = \"This movie was just way too overrated. The fighting was not professional and in slow motion. I was expecting more from a 200 million budget movie. The little sister of T.Challa was just trying too hard to be funny. The story was really dumb as well. Don't watch this movie if you are going because others say its great unless you are a Black Panther fan or Marvels fan.\"\n","\n","predict(test_input, model, word_to_index, index_to_tag)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Pb7OLSLzagi3","executionInfo":{"status":"ok","timestamp":1709454332835,"user_tz":-540,"elapsed":48,"user":{"displayName":"김재승","userId":"10280980096726140552"}},"outputId":"bc4d91f5-1631-4723-df93-cbb4fb6de672"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'부정'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["test_input = \" I was lucky enough to be included in the group to see the advanced screening in Melbourne on the 15th of April, 2012. And, firstly, I need to say a big thank-you to Disney and Marvel Studios. Now, the film... how can I even begin to explain how I feel about this film? It is, as the title of this review says a 'comic book triumph'. I went into the film with very, very high expectations and I was not disappointed. Seeing Joss Whedon's direction and envisioning of the film come to life on the big screen is perfect. The script is amazingly detailed and laced with sharp wit a humor. The special effects are literally mind-blowing and the action scenes are both hard-hitting and beautifully choreographed.\"\n","\n","predict(test_input, model, word_to_index, index_to_tag)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"dp1rsNpgahd6","executionInfo":{"status":"ok","timestamp":1709454333358,"user_tz":-540,"elapsed":567,"user":{"displayName":"김재승","userId":"10280980096726140552"}},"outputId":"6cf49459-ec94-4ac6-8fbc-40f818b2ddc1"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'긍정'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":[],"metadata":{"id":"HzZPV_-qaiIc"},"execution_count":null,"outputs":[]}]}